# -*- coding: utf-8 -*-
"""gaussian_blur_neumann_tr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JhreKmZ-3JPn3E_lwGzGcY2nwJVR_DDS

**Projet 4 Imagerie Computationnelle : Réseaux de Neuman pour la restauration d’image avec application aux
images ultrasonore**

**Etudiant 1: Tran Tuan-Vu**

**Etudiant 2: Neang Dany**

**networks/u_net.py**
"""

"""
Copyright (c) Facebook, Inc. and its affiliates.
This source code is licensed under the MIT license found in the
LICENSE file in the root directory of this source tree.
"""

import torch
from torch import nn
from torch.nn import functional as F


class ConvBlock(nn.Module):
    """
    A Convolutional Block that consists of two convolution layers each followed by
    instance normalization, LeakyReLU activation and dropout.
    """

    def __init__(self, in_chans, out_chans, drop_prob):
        """
        Args:
            in_chans (int): Number of channels in the input.
            out_chans (int): Number of channels in the output.
            drop_prob (float): Dropout probability.
        """
        super().__init__()

        self.in_chans = in_chans
        self.out_chans = out_chans
        self.drop_prob = drop_prob

        self.layers = nn.Sequential(
            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1, bias=False),
            nn.InstanceNorm2d(out_chans),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Dropout2d(drop_prob),
            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1, bias=False),
            nn.InstanceNorm2d(out_chans),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Dropout2d(drop_prob)
        )

    def forward(self, input):
        """
        Args:
            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]
        Returns:
            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]
        """
        return self.layers(input)


class TransposeConvBlock(nn.Module):
    """
    A Transpose Convolutional Block that consists of one convolution transpose layers followed by
    instance normalization and LeakyReLU activation.
    """

    def __init__(self, in_chans, out_chans):
        """
        Args:
            in_chans (int): Number of channels in the input.
            out_chans (int): Number of channels in the output.
        """
        super().__init__()

        self.in_chans = in_chans
        self.out_chans = out_chans

        self.layers = nn.Sequential(
            nn.ConvTranspose2d(in_chans, out_chans, kernel_size=2, stride=2, bias=False),
            nn.InstanceNorm2d(out_chans),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
        )

    def forward(self, input):
        """
        Args:
            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]
        Returns:
            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]
        """
        return self.layers(input)

class ZerosNet(nn.Module):
    def __init__(self):
        super(ZerosNet, self).__init__()

    def forward(self, input):
        return input*0.0 + 0.0

class UnetModel(nn.Module):
    """
    PyTorch implementation of a U-Net model.
    This is based on:
        Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks
        for biomedical image segmentation. In International Conference on Medical image
        computing and computer-assisted intervention, pages 234–241. Springer, 2015.
    """

    def __init__(self, in_chans, out_chans, chans, num_pool_layers, drop_prob):
        """
        Args:
            in_chans (int): Number of channels in the input to the U-Net model.
            out_chans (int): Number of channels in the output to the U-Net model.
            chans (int): Number of output channels of the first convolution layer.
            num_pool_layers (int): Number of down-sampling and up-sampling layers.
            drop_prob (float): Dropout probability.
        """
        super().__init__()

        self.in_chans = in_chans
        self.out_chans = out_chans
        self.chans = chans
        self.num_pool_layers = num_pool_layers
        self.drop_prob = drop_prob

        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])
        ch = chans
        for i in range(num_pool_layers - 1):
            self.down_sample_layers += [ConvBlock(ch, ch * 2, drop_prob)]
            ch *= 2
        self.conv = ConvBlock(ch, ch * 2, drop_prob)

        self.up_conv = nn.ModuleList()
        self.up_transpose_conv = nn.ModuleList()
        for i in range(num_pool_layers - 1):
            self.up_transpose_conv += [TransposeConvBlock(ch * 2, ch)]
            self.up_conv += [ConvBlock(ch * 2, ch, drop_prob)]
            ch //= 2

        self.up_transpose_conv += [TransposeConvBlock(ch * 2, ch)]
        self.up_conv += [
            nn.Sequential(
                ConvBlock(ch * 2, ch, drop_prob),
                nn.Conv2d(ch, self.out_chans, kernel_size=1, stride=1),
            )]

    def forward(self, input):
        """
        Args:
            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]
        Returns:
            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]
        """
        stack = []
        output = input

        # Apply down-sampling layers
        for i, layer in enumerate(self.down_sample_layers):
            output = layer(output)
            stack.append(output)
            output = F.avg_pool2d(output, kernel_size=2, stride=2, padding=0)

        output = self.conv(output)

        # Apply up-sampling layers
        for transpose_conv, conv in zip(self.up_transpose_conv, self.up_conv):
            downsample_layer = stack.pop()
            output = transpose_conv(output)

            # Reflect pad on the right/botton if needed to handle odd input dimensions.
            padding = [0, 0, 0, 0]
            if output.shape[-1] != downsample_layer.shape[-1]:
                padding[1] = 1  # Padding right
            if output.shape[-2] != downsample_layer.shape[-2]:
                padding[3] = 1  # Padding bottom
            if sum(padding) != 0:
                output = F.pad(output, padding, "reflect")

            output = torch.cat([output, downsample_layer], dim=1)
            output = conv(output)

        return output

"""**operators/operator.py**"""

import torch

class LinearOperator(torch.nn.Module):
    def __init__(self):
        super(LinearOperator, self).__init__()

    def forward(self, x):
        pass

    def adjoint(self, x):
        pass

    def gramian(self, x):
        return self.adjoint(self.forward(x))

class SelfAdjointLinearOperator(LinearOperator):
    def adjoint(self, x):
        return self.forward(x)

class Identity(SelfAdjointLinearOperator):
    def forward(self, x):
        return x

class OperatorPlusNoise(torch.nn.Module):
    def __init__(self, operator, noise_sigma):
        super(OperatorPlusNoise, self).__init__()
        self.internal_operator = operator
        self.noise_sigma = noise_sigma

    def forward(self, x):
        A_x = self.internal_operator(x)
        return A_x + self.noise_sigma * torch.randn_like(A_x)

"""**operators/blurs.py**"""

import numpy as np
import numbers
import math
import cv2
import torch
import torch.nn.functional as torchfunc

class GaussianBlur(LinearOperator):
    def __init__(self, sigma, kernel_size=5, n_channels=3, n_spatial_dimensions = 2):
        super(GaussianBlur, self).__init__()
        self.groups = n_channels
        if isinstance(kernel_size, numbers.Number):
            self.padding = int(math.floor(kernel_size/2))
            kernel_size = [kernel_size] * n_spatial_dimensions
        else:
            print('KERNEL SIZE MUST BE A SINGLE INTEGER - RECTANGULAR KERNELS NOT SUPPORTED AT THIS TIME')
            exit()
        self.gaussian_kernel = torch.nn.Parameter(self.create_gaussian_kernel(sigma, kernel_size, n_channels),
                                                  requires_grad=False)

    def create_gaussian_kernel(self, sigma, kernel_size, n_channels):
        kernel = 1
        meshgrids = torch.meshgrid([torch.arange(size, dtype=torch.float32) for size in kernel_size])
        for size, mgrid in zip(kernel_size, meshgrids):
            mean = (size - 1) / 2
            kernel *= torch.exp(-((mgrid - mean) / sigma) ** 2 / 2)

        # Make sure norm of values in gaussian kernel equals 1.
        kernel = kernel / torch.sum(kernel)

        # Reshape to depthwise convolutional weight
        kernel = kernel.view(1, 1, *kernel.size())
        kernel = kernel.repeat(n_channels, *[1] * (kernel.dim() - 1))
        return kernel

    def forward(self, x):
        return torchfunc.conv2d(x, weight=self.gaussian_kernel, groups=self.groups, padding=self.padding)

    def adjoint(self, x):
        return torchfunc.conv2d(x, weight=self.gaussian_kernel, groups=self.groups, padding=self.padding)

class SingleAngleMotionBlur(LinearOperator):
    def __init__(self, sigma, kernel_size=5, n_channels=3, n_spatial_dimensions = 2):
        super(SingleAngleMotionBlur, self).__init__()
        self.groups = n_channels
        if isinstance(kernel_size, numbers.Number):
            self.padding = int(math.floor(kernel_size/2))
            kernel_size = [kernel_size] * n_spatial_dimensions
        else:
            print('KERNEL SIZE MUST BE A SINGLE INTEGER - RECTANGULAR KERNELS NOT SUPPORTED AT THIS TIME')
            exit()
        self.blur_kernel = torch.nn.Parameter(self.create_gaussian_kernel(sigma, kernel_size, n_channels),
                                              requires_grad=False)

    def create_motionblur_kernel(self, angle, kernel_size, n_channels):
        kernel = np.zeros((kernel_size, kernel_size))
        kernel[(kernel_size - 1) // 2, :] = np.ones(kernel_size, dtype=np.float32)
        kernel = cv2.warpAffine(kernel, cv2.getRotationMatrix2D((kernel_size / 2 - 0.5, kernel_size / 2 - 0.5),
                                                                angle, 1.0), (kernel_size, kernel_size))
        kernel = torch.tensor(kernel, dtype=torch.float32)
        # Make sure norm of values in gaussian kernel equals 1.
        kernel = kernel / torch.sum(kernel)
        kernel = kernel.view(1, 1, *kernel.size())
        kernel = kernel.repeat(n_channels, *[1] * (kernel.dim() - 1))
        return kernel

    def forward(self, x):
        convolution_weight = self.blur_kernel
        return torchfunc.conv2d(x, weight=convolution_weight, groups=self.groups, padding=self.padding)

    def adjoint(self, x):
        convolution_weight = torch.transpose(self.blur_kernel, dim0=2, dim1=3)
        return torchfunc.conv2d(x, weight=convolution_weight, groups=self.groups, padding=self.padding)

"""**solvers/cg_utils.py**"""

import torch.nn as nn
import torch

def complex_conj(x):
    assert x.shape[1] == 2
    return torch.stack((x[:,0, ...], -x[:,1,...]), dim=1)

def torchdotproduct(x,y):
    # if complexdata:
    # y = complex_conj(y)
    return torch.sum(x*y,dim=[1,2,3])

def single_cg_iteration(x, d, g, b, ATA, regularization_lambda):

    def regATA(input, ATA):
        return ATA(input) + regularization_lambda*input

    Qd = regATA(d, ATA)
    dQd = torchdotproduct(d, Qd)
    alpha = -torchdotproduct(g,d) / dQd
    alpha = alpha.view((-1,1,1,1))
    x = x + alpha * d
    g = regATA(x, ATA) - b
    gQd = torchdotproduct(g, Qd)
    beta = gQd / dQd
    beta = beta.view((-1,1,1,1))
    d = -g + beta*d
    return x, d, g

# This function solves the system ATA x = ATy, where initial_point is supposed
# to be ATy. This can be backpropagated through.
def conjugate_gradient(initial_point, ATA, regularization_lambda, n_iterations=10):
    x = torch.zeros_like(initial_point)
    d = initial_point
    g = -d
    for ii in range(n_iterations):
        x, d, g = single_cg_iteration(x, d, g, initial_point, ATA, regularization_lambda)
    return x

def complex_dotproduct(x, y):
    return torchdotproduct(complex_conj(x), y)

def single_cg_iteration_MRI(rTr, x, r, p, ATA, regularization_lambda):

    batch_size = x.shape[0]
    def regATA(input):
        return ATA(input) + regularization_lambda*input

    Ap = regATA(p)

    rTr = rTr.view(batch_size, 1, 1, 1)
    alpha = rTr / complex_dotproduct(p, Ap).view(batch_size, 1, 1, 1)

    x_new = x + alpha * p
    r_new = r - alpha * Ap
    rTr_new = complex_dotproduct(r_new, r_new)
    rTr_new = rTr_new.view(batch_size, 1, 1, 1)

    beta = rTr_new / rTr
    p_new = r + beta * p
    return rTr_new, x_new, r_new, p_new

def conjugate_gradient_MRI(initial_point, ATA, regularization_lambda, n_iterations=10):
    '''Strightforward implementation of MoDLs code'''
    x = torch.zeros_like(initial_point)
    r = initial_point
    p = initial_point
    rTr = complex_dotproduct(r, r)
    for ii in range(n_iterations):
        rTr, x, r, p = single_cg_iteration_MRI(rTr, x, r, p, ATA, regularization_lambda)
    return x

"""**solvers/neumann.py**"""

import torch.nn as nn
import torch

class NeumannNet(nn.Module):
    def __init__(self, linear_operator, nonlinear_operator, eta_initial_val=0.1):
        super(NeumannNet,self).__init__()
        self.linear_op = linear_operator
        self.nonlinear_op = nonlinear_operator

        # Check if the linear operator has parameters that can be learned:
        # if so, register them to be learned as part of the network.
        linear_param_name = 'linear_param_'
        for ii, parameter in enumerate(self.linear_op.parameters()):
            parameter_name = linear_param_name + str(ii)
            self.register_parameter(name=parameter_name, param=parameter)

        self.register_parameter(name='eta', param=torch.nn.Parameter(torch.tensor(eta_initial_val), requires_grad=True))

    def _linear_op(self, x):
        return self.linear_op.forward(x)

    def _linear_adjoint(self, x):
        return self.linear_op.adjoint(x)

    # This is a bit redundant
    def initial_point(self, y):
        return self._linear_adjoint(y)

    def single_block(self, input):
        return input - self.eta * self.linear_op.gramian(input) - self.nonlinear_op(input)

    def forward(self, y, iterations):
        initial_point = self.eta * self.initial_point(y)
        running_term = initial_point
        accumulator = initial_point

        for bb in range(iterations):
            running_term = self.single_block(running_term)
            accumulator = accumulator + running_term

        return accumulator

class PrecondNeumannNet(nn.Module):
    def __init__(self, linear_operator, nonlinear_operator, lambda_initial_val=0.1, cg_iterations=10):
        super(PrecondNeumannNet,self).__init__()
        self.linear_op = linear_operator
        self.nonlinear_op = nonlinear_operator
        self.cg_iterations = cg_iterations

        # Check if the linear operator has parameters that can be learned:
        # if so, register them to be learned as part of the network.
        linear_param_name = 'linear_param_'
        for ii, parameter in enumerate(self.linear_op.parameters()):
            parameter_name = linear_param_name + str(ii)
            self.register_parameter(name=parameter_name, param=parameter)

        self.register_parameter(name='eta', param=torch.nn.Parameter(torch.tensor(lambda_initial_val), requires_grad=True))

    def _linear_op(self, x):
        return self.linear_op.forward(x)

    def _linear_adjoint(self, x):
        return self.linear_op.adjoint(x)

    # This is a bit redundant
    def initial_point(self, y):
        preconditioned_input = conjugate_gradient(y, self.linear_op.gramian, regularization_lambda=self.eta,
                                                  n_iterations=self.cg_iterations)
        return preconditioned_input

    def single_block(self, input):
        preconditioned_step = conjugate_gradient(input, self.linear_op.gramian, regularization_lambda=self.eta,
                                                  n_iterations=self.cg_iterations)
        return self.eta * preconditioned_step - self.nonlinear_op(input)

    def forward(self, y, iterations):
        initial_point = self.eta * self.initial_point(y)
        running_term = initial_point
        accumulator = initial_point

        for bb in range(iterations):
            running_term = self.single_block(running_term)
            accumulator = accumulator + running_term

        return accumulator

"""**training/standard_training.py**"""

import torch
import numpy as np

def train_solver(solver, train_dataloader,
                 measurement_process, optimizer,
                 save_location, loss_function, n_epochs,
                 use_dataparallel=False, device='cpu', scheduler=None,
                 print_every_n_steps=10, save_every_n_epochs=5, start_epoch=0):

    for epoch in range(start_epoch, n_epochs):

        # We are lucky to have
        if epoch % save_every_n_epochs == 0:
            if use_dataparallel:
                torch.save({'solver_state_dict': solver.module.state_dict(),
                            'epoch': epoch,
                            'optimizer_state_dict': optimizer.state_dict(),
                            'scheduler_state_dict': scheduler.state_dict()
                            }, save_location)
            else:
                torch.save({'solver_state_dict': solver.state_dict(),
                            'epoch': epoch,
                            'optimizer_state_dict': optimizer.state_dict(),
                            'scheduler_state_dict': scheduler.state_dict()
                            }, save_location)

        for ii, sample_batch in enumerate(train_dataloader):
            optimizer.zero_grad()

            sample_batch = sample_batch.to(device=device)
            y = measurement_process(sample_batch)
            initial_point = y
            reconstruction = solver(initial_point, iterations=6)

            reconstruction = torch.clamp(reconstruction, -1 ,1)

            loss = loss_function(reconstruction, sample_batch)

            loss.backward()
            optimizer.step()

            if ii % print_every_n_steps == 0:
                logging_string = "Epoch: " + str(epoch) + " Step: " + str(ii) + \
                                 " Loss: " + str(loss.cpu().detach().numpy())
                print(logging_string, flush=True)

        if scheduler is not None:
            scheduler.step(epoch)

    #####################TEST##########################
    # loss_accumulator = []
    # mse_loss = torch.nn.MSELoss()
    # for ii, sample_batch in enumerate(test_dataloader):
    #     sample_batch = sample_batch.to(device=device)
    #     y = measurement_process(sample_batch)
    #     initial_point = y
    #     reconstruction = solver(initial_point, iterations=6)

    #     reconstruction = torch.clamp(reconstruction, -1 ,1)

    #     loss = mse_loss(reconstruction, sample_batch)
    #     loss_logger = loss.cpu().detach().numpy()
    #     loss_accumulator.append(loss_logger)

    # loss_array = np.asarray(loss_accumulator)
    # loss_mse = np.mean(loss_array)
    # PSNR = -10 * np.log10(loss_mse)
    # percentiles = np.percentile(loss_array, [25,50,75])
    # percentiles = -10.0*np.log10(percentiles)
    # print("TEST LOSS: " + str(sum(loss_accumulator) / len(loss_accumulator)), flush=True)
    # print("MEAN TEST PSNR: " + str(PSNR), flush=True)
    # print("TEST PSNR QUARTILES AND MEDIAN: " + str(percentiles[0]) +
    #       ", " + str(percentiles[1]) + ", " + str(percentiles[2]), flush=True)

"""  **utils/celeba_dataloader.py**"""

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import os, re, random
from PIL import Image

def swap_patches(batch, index1, index2, h,w, patch_top_loc, patch_left_loc):
    tmp = batch[
       index1,
       patch_top_loc:patch_top_loc+h,
       patch_left_loc:patch_left_loc+w, :].clone()

    batch[
         index1,
         patch_top_loc:patch_top_loc+h,
         patch_left_loc:patch_left_loc+w, :] = batch[
             index2,
             patch_top_loc:patch_top_loc+h,
             patch_left_loc:patch_left_loc+w, :].clone()

    batch[
         index1,
         patch_top_loc:patch_top_loc+h,
         patch_left_loc:patch_left_loc+w, :] = tmp
 
    return batch

   


#TODO this should probably be moved to another file as it's a transform
# Although it needs to operate on the batch as opposed to individual images
def batch_patch_swap(batch, h=None, w=None, ):
    '''
    Args:
        batch: batch x h x w x ch of images of type torch tensor
        h: height of patch to be swapped, if greater than batch.size()[1] then will be capped to that
        w: width of patch, similar capping will be done as height

    '''
    #TODO maybe we specify h and w as a range instead?
    num_images, height, width, _ = batch.size()
    #TODO maybe crop from different locations of the image?
    patch_top_loc = random.randint(1, int((3.0/4)*height))
    patch_left_loc = random.randint(1, int((3.0/4)*width))

    if (not h) or (h >= height) or (h + patch_top_loc >= height):
        h = random.randint(1, height-patch_top_loc)
    if (not w) or (w >= width):
        h = random.randint(1, width-patch_left_loc)

    for index in range(num_images):
        swap_index = random.randint(0, num_images-1)
        batch = swap_patches(batch, index, swap_index, h,w, patch_top_loc, patch_left_loc)

    return batch

def sorted_nicely(l):
    convert = lambda text: int(text) if text.isdigit() else text
    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]
    return sorted(l, key=alphanum_key)

def directory_filelist(target_directory):
    file_list = [f for f in sorted(os.listdir(target_directory))
                 if os.path.isfile(os.path.join(target_directory, f))]
    file_list = list(file_list)
    file_list = [f for f in file_list if not f.startswith('.')]
    return file_list

def load_img(file_name):
    with open(file_name,'rb') as f:
        img = Image.open(f).convert("RGB")
    return img

class FolderDataset(Dataset):
    def __init__(self, target_directory, transform=None):
        filelist = directory_filelist(target_directory)
        self.full_filelist = [target_directory + single_file for single_file in filelist]
        self.transform = transform

    def __len__(self):
        return len(self.full_filelist)

    def __getitem__(self, item):
        image_name = self.full_filelist[item]
        data = load_img(image_name)
        if self.transform is not None:
            data = self.transform(data)
        return data

class CelebaDataset(Dataset):
    def __init__(self, target_directory, validation_data=False, transform=None):
        filelist = directory_filelist(target_directory)
        training_data = filelist[:580]
        val_data = filelist[580:620]
        test_data = filelist[620:]
        if validation_data:
            self.full_filelist = [target_directory + single_file for single_file in val_data]
        else:
            self.full_filelist = [target_directory + single_file for single_file in training_data]

        self.transform = transform

    def __len__(self):
        return len(self.full_filelist)

    def __getitem__(self, item):
        image_name = self.full_filelist[item]
        data = load_img(image_name)
        if self.transform is not None:
            data = self.transform(data)
        return data

class CelebaTrainingDatasetSubset(Dataset):
    def __init__(self, target_directory, subset_indices, transform=None):
        filelist = directory_filelist(target_directory)
        training_data = filelist[:580]
        try:
            training_data = [training_data[x] for x in subset_indices]
        except TypeError:
            training_data = [training_data[subset_indices]]

        self.full_filelist = [target_directory + single_file for single_file in training_data]

        self.transform = transform

    def __len__(self):
        return len(self.full_filelist)

    def __getitem__(self, item):
        image_name = self.full_filelist[item]
        data = load_img(image_name)
        if self.transform is not None:
            data = self.transform(data)
        return data

# This can be removed I think it's the same class as the one above at least right now.
class CelebaTestDataset(Dataset):
    def __init__(self, target_directory, transform=None):
        filelist = directory_filelist(target_directory)
        training_data = filelist[:580]
        val_data = filelist[580:620]
        test_data = filelist[620:]
        self.full_filelist = [target_directory + single_file for single_file in test_data]
        self.transform = transform

    def __len__(self):
        return len(self.full_filelist)

    def __getitem__(self, item):
        image_name = self.full_filelist[item]
        data = load_img(image_name)
        if self.transform is not None:
            data = self.transform(data)
        return data

"""**utils/fastmri_dataloader.py**"""

!pip install ismrmrd

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import os, re, random, h5py, ismrmrd
from PIL import Image
from torch.utils.data import Dataset

def directory_filelist(target_directory):
    file_list = [f for f in os.listdir(target_directory)
                 if os.path.isfile(os.path.join(target_directory, f))]
    file_list = list(file_list)
    file_list = [f for f in file_list if not f.startswith('.')]
    return file_list

def to_tensor(data):
    """
    Convert numpy array to PyTorch tensor. For complex arrays, the real and imaginary parts
    are stacked along the last dimension.
    Args:
        data (np.array): Input numpy array
    Returns:
        torch.Tensor: PyTorch version of data
    """
    if np.iscomplexobj(data):
        data = np.stack((data.real, data.imag), axis=-1)
    return torch.from_numpy(data)

def center_crop_slice(data, shape):
    """
    Apply a center crop to the input real image or batch of real images.
    Args:
        data (torch.Tensor): The input tensor to be center cropped. It should have at
            least 2 dimensions and the cropping is applied along the last two dimensions.
        shape (int, int): The output shape. The shape should be smaller than the
            corresponding dimensions of data.
    Returns:
        torch.Tensor: The center cropped image
    """
    assert 0 < shape[0] <= data.shape[0]
    assert 0 < shape[1] <= data.shape[1]
    w_from = (data.shape[0] - shape[0]) // 2
    h_from = (data.shape[1] - shape[1]) // 2
    w_to = w_from + shape[0]
    h_to = h_from + shape[1]
    return data[w_from:w_to, h_from:h_to, ...]

def complex_abs(data):
    """
    Compute the absolute value of a complex valued input tensor.
    Args:
        data (torch.Tensor): A complex valued tensor, where the size of the final dimension
            should be 2.
    Returns:
        torch.Tensor: Absolute value of data
    """
    assert data.size(-1) == 2
    return (data ** 2).sum(dim=-1).sqrt()

class singleCoilFastMRIDataloader(Dataset):
    def __init__(self, dataset_location, transform=None, data_indices=None, sketchynormalize=True):
        """
        Args:
            mask_func (common.subsample.MaskFunc): A function that can create a mask of
                appropriate shape.
            resolution (int): Resolution of the image.
            use_seed (bool): If true, this class computes a pseudo random number generator seed
                from the filename. This ensures that the same mask is used for all the slices of
                a given volume every time.
        """
        self.transform = transform
        if data_indices is not None:
            filelist = directory_filelist(dataset_location)
            print(len(filelist))
            try:
                self.filelist = [filelist[x] for x in data_indices]
            except IndexError:
                print(data_indices)
                exit()
        else:
            self.filelist = directory_filelist(dataset_location)
        self.data_directory = dataset_location
        self.fft = forward_models_mri.toKspace()
        self.ifft = forward_models_mri.fromKspace()
        self.sketchynormalize = sketchynormalize

    def __len__(self):
        return len(self.filelist)

    def __getitem__(self, item):
        """
        Args:
            kspace (numpy.array): Input k-space of shape (num_coils, rows, cols, 2) for multi-coil
                data or (rows, cols, 2) for single coil data.
            mask (numpy.array): Mask from the test dataset
            target (numpy.array): Target image
            attrs (dict): Acquisition related information stored in the HDF5 object.
            fname (str): File name
            slice (int): Serial number of the slice.
        Returns:
            (tuple): tuple containing:
                image (torch.Tensor): Zero-filled input image.
                target (torch.Tensor): Target image converted to a torch Tensor.
                mean (float): Mean value used for normalization.
                std (float): Standard deviation value used for normalization.
        """
        filename = self.filelist[item]
        data = h5py.File(self.data_directory + filename, 'r')
        print(str(item) + ": " + str(filename))

        kspace = to_tensor(data.get('kspace').value)
        image_space = forward_models_mri.ifft2(kspace)
        image_space = center_crop_slice(image_space, shape=[320, 320]).permute((2,0,1))


        if self.sketchynormalize:
            # don't ask
            # image_space *= 666.666
            image_space *= 2000

            image_space = image_space.clamp(min=-1, max=1)


        return image_space

"""**utils/testing_utils.py**"""

from PIL import Image
import torch
import matplotlib.pyplot as plt
import numpy as np
import imageio

def save_tensor_as_color_img(img_tensor, filename):
    np_array = img_tensor.cpu().detach().numpy()
    imageio.save(filename, np_array)

def save_batch_as_color_imgs(tensor_batch, batch_size, ii, folder_name, names):
    # img_array = (np.transpose(tensor_batch.cpu().detach().numpy(),(0,2,3,1)) + 1.0) *  127.5
    img_array = (np.clip(np.transpose(tensor_batch.cpu().detach().numpy(),(0,2,3,1)),-1,1) + 1.0) *  127.5
    # img_array = tensor_batch.cpu().detach().numpy()
    # print(np.max(img_array[:]))
    # print(np.min(img_array[:]))

    img_array = img_array.astype(np.uint8)
    for kk in range(batch_size):
        img_number = batch_size*ii + kk
        filename = folder_name + str(img_number) + "_" + str(names[kk]) + ".png"
        # print(np.shape(img_array))
        # print(filename)
        imageio.imwrite(filename, img_array[kk,...])

def save_mri_as_imgs(tensor_batch, batch_size, ii, folder_name, names):
    # img_array = (np.transpose(tensor_batch.cpu().detach().numpy(),(0,2,3,1)) + 1.0) *  127.5
    img_array = tensor_batch.cpu().detach().numpy()

    for kk in range(batch_size):
        img_number = batch_size*ii + kk
        filename = folder_name + str(img_number) + "_" + str(names[kk]) + ".png"
        plt.imshow(np.sqrt(img_array[kk,0,:,:]**2 + img_array[kk,1,:,:]**2))
        plt.gray()
        plt.xticks([])
        plt.yticks([])
        plt.savefig(filename, bbox_inches='tight')

"""**Connection to Drive**"""

from google.colab import drive
drive.mount('/content/drive')

#ajouter le drive dans votre drive pour les chemins
path = "/content/drive/My Drive/projet_imagerie/"
dataset_location = path+"ui_dataset/"
output_image_location = path+"result_test/gaussian_blur_neumann/"
trained_model = path+"trained_model/"

"""**testing/standard_testing.py**"""

import torch
import numpy as np

def test_solver(solver, test_dataloader, measurement_process, device='cpu', batch_size=1):

    #####################TEST##########################
    loss_accumulator = []
    mse_loss = torch.nn.MSELoss()
    for ii, sample_batch in enumerate(test_dataloader):
        # save image 1
        save_batch_as_color_imgs(sample_batch, batch_size, ii, output_image_location, ["1"])

        sample_batch = sample_batch.to(device=device)
        y = measurement_process(sample_batch)
        initial_point = y

        # save image 2
        save_batch_as_color_imgs(y, batch_size, ii, output_image_location, ["blur_neumann"])

        reconstruction = solver(initial_point, iterations=6)

        reconstruction = torch.clamp(reconstruction, -1 ,1)

        # save image 3
        save_batch_as_color_imgs(reconstruction, batch_size, ii, output_image_location, ["recon_blur_neumann"])

        loss = mse_loss(reconstruction, sample_batch)
        loss_logger = loss.cpu().detach().numpy()
        loss_accumulator.append(loss_logger)
        logging_string = "Loss: " + str(loss.cpu().detach().numpy())
        print(logging_string)
        if ii > 2:
            exit()

    loss_array = np.asarray(loss_accumulator)
    loss_mse = np.mean(loss_array)
    PSNR = -10 * np.log10(loss_mse)
    percentiles = np.percentile(loss_array, [25,50,75])
    percentiles = -10.0*np.log10(percentiles)
    print("TEST LOSS: " + str(sum(loss_accumulator) / len(loss_accumulator)), flush=True)
    print("MEAN TEST PSNR: " + str(PSNR), flush=True)
    print("TEST PSNR QUARTILES AND MEDIAN: " + str(percentiles[0]) +
          ", " + str(percentiles[1]) + ", " + str(percentiles[2]), flush=True)

"""**scripts/gaussian_blur_neumann.py**

**Training the model**
"""

import torch
import os
import random
import sys
#sys.path.append('/home-nfs/gilton/learned_iterative_solvers')
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms

# Parameters to modify
n_epochs = 3
current_epoch = 1
batch_size = 1 #16
n_channels = 3
learning_rate = 0.001
print_every_n_steps = 100
save_every_n_epochs = 3
initial_eta = 0.1

initial_data_points = 400
# point this towards your celeba files
data_location = dataset_location

kernel_size = 5
noise_sigma = 0.01

# modify this for your machine
save_location = trained_model+"gaussianblur_neumann.ckpt"

gpu_ids = []
for ii in range(6):
    try:
        torch.cuda.get_device_properties(ii)
        print(str(ii), flush=True)
        if not gpu_ids:
            gpu_ids = [ii]
        else:
            gpu_ids.append(ii)
    except AssertionError:
        print('Not ' + str(ii) + "!", flush=True)

print(os.getenv('CUDA_VISIBLE_DEVICES'), flush=True)
gpu_ids = [int(x) for x in gpu_ids]
# device management
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
use_dataparallel = len(gpu_ids) > 1
print("GPU IDs: " + str([int(x) for x in gpu_ids]), flush=True)

# Set up data and dataloaders
transform = transforms.Compose(
    [
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ]
)
celeba_train_size = 580
total_data = initial_data_points
total_indices = random.sample(range(celeba_train_size-1), k=total_data)
initial_indices = total_indices
#print(initial_indices)
dataset = CelebaTrainingDatasetSubset(data_location, subset_indices=initial_indices, transform=transform)
dataloader = torch.utils.data.DataLoader(
    dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True,
)

### Set up solver and problem setting

forward_operator = GaussianBlur(sigma=5.0, kernel_size=kernel_size,
                                      n_channels=3, n_spatial_dimensions=2).to(device=device)
measurement_process = OperatorPlusNoise(forward_operator, noise_sigma=noise_sigma).to(device=device)

internal_forward_operator = GaussianBlur(sigma=5.0, kernel_size=kernel_size,
                                      n_channels=3, n_spatial_dimensions=2).to(device=device)

# standard u-net
learned_component = UnetModel(in_chans=n_channels, out_chans=n_channels, num_pool_layers=4,
                                       drop_prob=0.0, chans=32)
solver = NeumannNet(linear_operator=internal_forward_operator, nonlinear_operator=learned_component,
                    eta_initial_val=initial_eta)

if use_dataparallel:
    solver = nn.DataParallel(solver, device_ids=gpu_ids)
solver = solver.to(device=device)

start_epoch = 0
optimizer = optim.Adam(params=solver.parameters(), lr=learning_rate)
scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=40, gamma=0.1)
cpu_only = not torch.cuda.is_available()


if os.path.exists(save_location):
    if not cpu_only:
        saved_dict = torch.load(save_location)
    else:
        saved_dict = torch.load(save_location, map_location='cpu')

    start_epoch = saved_dict['epoch']
    solver.load_state_dict(saved_dict['solver_state_dict'])
    optimizer.load_state_dict(saved_dict['optimizer_state_dict'])
    scheduler.load_state_dict(saved_dict['scheduler_state_dict'])


# set up loss and train
lossfunction = torch.nn.MSELoss()

# Do train
train_solver(solver=solver, train_dataloader=dataloader,
            measurement_process=measurement_process, optimizer=optimizer, save_location=save_location,
            loss_function=lossfunction, n_epochs=n_epochs, use_dataparallel=use_dataparallel,
            device=device, scheduler=scheduler, print_every_n_steps=print_every_n_steps,
            save_every_n_epochs=save_every_n_epochs, start_epoch=start_epoch)

"""**testing/gaussian_blur_neumann.py**

**Testing the model**
"""

import torch
import os
import random
import sys
#sys.path.append('/home-nfs/gilton/learned_iterative_solvers')
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms

test_dataset = CelebaTestDataset(data_location, transform=transform)
test_dataloader = torch.utils.data.DataLoader(
    dataset=test_dataset, batch_size=batch_size, shuffle=False, drop_last=True,
)

# Do test
test_solver(solver=solver, test_dataloader=test_dataloader, 
                               measurement_process=measurement_process, device=device, batch_size=batch_size)

